`Prometheus Federation` 允许一台 `Prometheus Server` 从另一台 `Prometheus Server` 刮取选定的[时间序列](https://so.csdn.net/so/search?q=%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97&spm=1001.2101.3001.7020)资料

##  分层联邦示例
```
scrape_configs:
  - job_name: 'federate'
    scrape_interval: 60s # 为了解决报错 “context deadline exceeded”
    scrape_timeout: 60s  # 不能大于上方间隔
    honor_labels: true
    metrics_path: '/federate'
    params:
      'match[]':
        - '{job="kubernetes-service-endpoints"}'  # 此处使用的标签不是自动发现的源标签，是prometheus targets 使用的现有的 "job" 标签
        - '{job="kubernetes-pods"}'
        - '{job="vault-internal"}' 
        - '{job="ak-outpost-proxy"}'
        - '{job="kube-controller-manager"}'
        - '{job="kube-etcd"}'
        - '{job="kube-proxy"}'
        - '{job="kube-scheduler"}'
        - '{job="kube-state-metrics"}'
        - '{job="rancher-monitoring-operator"}'
        - '{job="rancher-monitoring-prometheus"}'
        - '{job="apiserver"}'
        - '{job="coredns"}'
        - '{job="ingress-nginx"}'
        - '{job="kubelet"}'
        - '{__name__=~".*:.*"}'    #__name__: 这是一个内置的标签，用于表示指标的名称; 这个已经包含以下的类型的所有指标
        - '{__name__=~"code_resource:.*"}'  # 可以不再匹配
        - '{__name__=~"cluster_quantile:.*"}'
    static_configs:
      - targets:
        - 'monitorprom.testlab.net'
        labels:                          # 为指标集群来源做区分
          cluster: 'monitor'
      - targets:
        - 'testprometheus.testlab.net'
        labels:
          cluster: 'test-sys'
```

>[!important] 
> prom pull 指标的 url 会报错 “context deadline exceeded”，这很可能是因为抓取指标的周期有问题，增加一下时间间隔

## 问题：
在来源于多个集群的指标中，没有标签来区别这些指标的源集群是哪一个
### 发现和区分源集群的三种方式
- 上游管理集群的 crd 资源;  但是不知道怎么样可以便捷的传递到下游集群的 prom 并添加标签。
```
kubectl get projects -A -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,DISPLAY NAME:.spec.displayName,AGE:.metadata.creationTimestamp'
NAMESPACE      NAME      DISPLAY NAME                AGE
c-m-2z2cnbsd   p-6v2s8   Default                     2024-04-18T09:28:34Z
c-m-2z2cnbsd   p-8tbr6   test-ops-kuberay-clusters   2024-04-19T07:57:12Z
c-m-2z2cnbsd   p-h28dj   System                      2024-04-18T09:28:34Z
c-m-2z2cnbsd   p-p9v9p   test-ops-app                2024-04-19T07:57:12Z
c-m-2z2cnbsd   p-vvh6s   test-ops-system             2024-04-19T07:57:12Z
c-m-jgf7h56m   p-gpddg   Default                     2024-03-31T06:54:49Z
c-m-jgf7h56m   p-mlt46   monitor                     2024-04-01T09:15:28Z
c-m-jgf7h56m   p-vqdnp   System                      2024-03-31T06:54:49Z
c-m-rlxncp5h   p-5gqjt   test-sys-app                2024-01-05T07:51:56Z
c-m-rlxncp5h   p-5r9vn   test-sys-system             2024-01-05T07:51:49Z
c-m-rlxncp5h   p-jf9jd   System                      2024-01-05T07:15:44Z
c-m-rlxncp5h   p-nrndb   Default                     2024-01-05T07:15:44Z
local          p-fzj62   System                      2024-01-05T07:10:21Z
local          p-hpqrm   Default                     2024-01-05T07:1
```

- 在发现的指标的元数据中

`具有这个元标签"__meta_kubernetes_pod_node_name: 特定的主机名"，但是复杂在于sd配置和servicemonitor需要重新配置 label reconfig；servicemonitor 标签处理需要进一步学习 `

- 是否可以在 federation 的时候，区分不同的源并添加标签。

  测试有效,当前在采用这样的方式给集群手动添加静态的标签！